# TONL-MCP Bridge üåâ

> Reduce LLM token costs by 30-60% with TONL format

[![npm version](https://img.shields.io/npm/v/tonl-mcp-bridge.svg)](https://www.npmjs.com/package/tonl-mcp-bridge)
[![Tests](https://github.com/kryptomrx/tonl-mcp-bridge/actions/workflows/test.yml/badge.svg)](https://github.com/kryptomrx/tonl-mcp-bridge/actions/workflows/test.yml)
[![codecov](https://codecov.io/gh/kryptomrx/tonl-mcp-bridge/graph/badge.svg?token=DEIN_TOKEN)](https://codecov.io/gh/kryptomrx/tonl-mcp-bridge)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/npm/l/tonl-mcp-bridge.svg)](https://github.com/kryptomrx/tonl-mcp-bridge/blob/main/LICENSE)

## What is this?

A TypeScript library and CLI tool that converts JSON/YAML data to TONL (Token Optimized Natural Language) format, reducing token usage for modern LLMs (GPT-5, Claude 4, Gemini 2.5).

**Perfect for:**
- ü§ñ RAG systems with structured data
- üìä Sending tabular data to LLMs
- üí¨ AI applications with repetitive JSON structures
- üìù Prompt libraries and configuration files

## The Problem

When sending structured data to LLMs, JSON is verbose:
```json
[
  {
    "id": 1,
    "name": "Alice",
    "age": 25,
    "active": true
  },
  {
    "id": 2,
    "name": "Bob",
    "age": 30,
    "active": false
  }
]
```

**56 tokens** (GPT-5 tokenizer) üí∏

## The Solution

TONL format is compact and structured:
```tonl
data[2]{id:i8,name:str,age:i8,active:bool}:
  1, Alice, 25, true
  2, Bob, 30, false
```

**37 tokens** ‚úÖ

**Result: 33.9% token savings!**

## Key Features

‚úÖ **Bidirectional Conversion**
- JSON ‚Üî TONL with lossless round-trip
- YAML ‚Üî TONL for configuration files
- Schema validation across all objects

‚úÖ **Extended Type System** (v0.2.0)
- Integers: `i8`, `i16`, `i32`, `i64` (automatic optimization)
- Floats: `f32`, `f64`
- Special: `date`, `datetime`
- Automatic type detection and smallest type selection

‚úÖ **Real Token Counting**
- Integrated tokenizer with 2025 AI models (js-tiktoken)
- Accurate token statistics (not estimation!)
- Support for GPT-5, Claude 4, Gemini 2.5, and more

‚úÖ **Production Ready**
- 44/44 unit tests passing
- Full TypeScript support
- Error handling with detailed messages
- String escaping for special characters

## Installation

### Global (CLI)
```bash
npm install -g tonl-mcp-bridge
```

### Local (Library)
```bash
npm install tonl-mcp-bridge
```

## CLI Usage

### Basic Conversion
```bash
# JSON ‚Üí TONL
tonl convert data.json

# With real token statistics
tonl convert data.json -s
```

**Output:**
```
üìÑ Converting JSON ‚Üí TONL...
‚úÖ Converted successfully!
üìÅ Output: data.tonl

üìä Token Statistics (GPT 5 Tokenizer):
   Input:  56 tokens
   Output: 37 tokens
   Saved:  19 tokens (33.9%)
```

### YAML Support
```bash
tonl convert prompts.yaml -s
```

### Convert Back
```bash
# TONL ‚Üí JSON
tonl convert data.tonl

# TONL ‚Üí YAML
tonl convert data.tonl output.yaml
```

### Options
```bash
# Custom collection name
tonl convert users.json --name users

# Specify output path
tonl convert input.json output.tonl
```

## Programmatic Usage

### JSON ‚Üí TONL
```typescript
import { jsonToTonl } from 'tonl-mcp-bridge';

const users = [
  { id: 1, name: "Alice", score: 19.99 },
  { id: 2, name: "Bob", score: 25.50 }
];

const tonl = jsonToTonl(users, "users");
console.log(tonl);
// users[2]{id:i8,name:str,score:f32}:
//   1, Alice, 19.99
//   2, Bob, 25.5
```

### TONL ‚Üí JSON
```typescript
import { tonlToJson } from 'tonl-mcp-bridge';

const tonl = `users[2]{id:i8,name:str}:
  1, Alice
  2, Bob`;

const json = tonlToJson(tonl);
// [
//   { id: 1, name: "Alice" },
//   { id: 2, name: "Bob" }
// ]
```

### Real Token Counting
```typescript
import { calculateRealSavings } from 'tonl-mcp-bridge';

const jsonStr = JSON.stringify(data);
const tonlStr = jsonToTonl(data);

const savings = calculateRealSavings(jsonStr, tonlStr, 'gpt-5');

console.log(`Original: ${savings.originalTokens} tokens`);
console.log(`TONL: ${savings.compressedTokens} tokens`);
console.log(`Saved: ${savings.savedTokens} tokens (${savings.savingsPercent}%)`);
```

### YAML Conversion
```typescript
import { yamlToTonl, tonlToYaml } from 'tonl-mcp-bridge';

// YAML ‚Üí TONL
const yamlStr = `
- role: storyteller
  context: fantasy
  tone: dramatic
`;

const tonl = yamlToTonl(yamlStr, 'prompts');

// TONL ‚Üí YAML (round-trip)
const yaml = tonlToYaml(tonl);
```

## When to Use TONL

### ‚úÖ TONL Works Best For:

- **10+ similar objects** with consistent schema
- **Tabular data** (user lists, transactions, logs)
- **Large datasets** (100s-1000s of items)
- **Repetitive structures** (same keys repeated)

### ‚ùå Don't Use TONL For:

- **Single objects** (header overhead)
- **1-5 items** (minimal savings)
- **Highly nested data** (loses structure)
- **Varied schemas** (different keys per object)

### Real Benchmarks (GPT-5 Tokenizer)

| Items | JSON Tokens | TONL Tokens | Savings |
|-------|-------------|-------------|---------|
| 1     | 18          | 23          | -27.8% ‚ùå |
| 2     | 56          | 37          | 33.9% ‚úÖ |
| 10    | 280         | 165         | 41.1% ‚úÖ |
| 100   | 2,800       | 1,450       | 48.2% üî• |
| 1000  | 28,000      | 14,000      | 50.0% üî• |

**Sweet spot: 10+ items with consistent schema**

## Extended Type System (v0.2.0)

TONL now automatically optimizes number types:
```typescript
// Automatic type optimization
{ id: 1 }         ‚Üí i8   (1 byte, -128 to 127)
{ id: 1000 }      ‚Üí i16  (2 bytes, -32K to 32K)
{ id: 100000 }    ‚Üí i32  (4 bytes, -2B to 2B)
{ price: 19.99 }  ‚Üí f32  (32-bit float)
{ created: "2024-01-15" } ‚Üí date
```

**Why?** Smaller types = fewer characters = fewer tokens!

**Supported Types:**
- Integers: `i8`, `i16`, `i32`, `i64`
- Floats: `f32`, `f64`
- Strings: `str`
- Booleans: `bool`
- Special: `date`, `datetime`, `null`

## Real-World Example

**Scenario:** Sending user data to LLM for analysis
```json
// users.json (100 users)
[
  {
    "id": 1,
    "name": "Alice Johnson",
    "email": "alice@example.com",
    "age": 25,
    "score": 87.5,
    "active": true,
    "created": "2024-01-15"
  },
  // ... 99 more
]
```

**Results:**
- JSON: ~2,800 tokens
- TONL: ~1,450 tokens
- **Savings: 48.2%** (1,350 tokens)

**Cost Impact (GPT-4 pricing):**
- Input: $0.03 per 1K tokens
- 1,350 tokens saved = **$0.04 per request**
- At 1000 requests/day = **$40/day = $1,200/month saved** üí∞

## Development
```bash
# Clone
git clone https://github.com/kryptomrx/tonl-mcp-bridge.git
cd tonl-mcp-bridge

# Install
npm install

# Test
npm test

# Build
npm run build

# Test CLI
node dist/cli/index.js convert test.json -s
```

## Roadmap

### ‚úÖ v0.2.1 (Current)
- [x] Support for 2025 AI models (GPT-5, Claude 4, Gemini 2.5)
- [x] Dynamic model display in CLI
- [x] Extended type system (i8-i64, f32-f64, date, datetime)
- [x] Real tokenizer integration (GPT-5, Claude, Gemini)
- [x] Schema validation across all objects
- [x] Lossless round-trip conversion
- [x] 45/45 tests passing

### üöß v0.3.0 (Next)
- [ ] `--model` flag (choose GPT-5, Claude 4, Gemini, etc.)
- [ ] `--validate` flag for schema checking
- [ ] Streaming API for large files
- [ ] Performance benchmarks vs alternatives

### üéØ v0.5.0 (Future)
- [ ] MCP Server implementation (auto-TONL gateway!)
- [ ] Batch processing
- [ ] Progress bars for large conversions
- [ ] OpenWebUI integration

### üíé v1.0.0 (Production)
- [ ] Full test coverage
- [ ] Documentation site
- [ ] Community examples
- [ ] Performance optimization

## Tech Stack

- **TypeScript 5.3** - Type safety
- **Vitest** - Fast testing
- **js-tiktoken** - Real tokenizer for GPT-5, Claude, Gemini
- **Commander.js** - CLI framework
- **js-yaml** - YAML parsing
- **Node.js 18+** - Modern runtime

## Contributing

Contributions welcome! Please:

1. Fork the repo
2. Create feature branch (`git checkout -b feature/cool-thing`)
3. Commit changes (`git commit -m 'Add cool thing'`)
4. Push (`git push origin feature/cool-thing`)
5. Open Pull Request

## Known Limitations

- **Single objects:** May not save tokens (header overhead)
- **Nested objects:** Not optimized (use flat structures)
- **Mixed schemas:** Less efficient (keys must be consistent)
- **Very small datasets:** JSON might be smaller

## License

MIT ¬© [kryptomrx](https://github.com/kryptomrx)

## Links

- **npm:** https://www.npmjs.com/package/tonl-mcp-bridge
- **GitHub:** https://github.com/kryptomrx/tonl-mcp-bridge
- **Issues:** https://github.com/kryptomrx/tonl-mcp-bridge/issues

---

**Built by a dev tired of wasting tokens on verbose JSON** üöÄ

*Saved you money? Give it a ‚≠ê on GitHub!*